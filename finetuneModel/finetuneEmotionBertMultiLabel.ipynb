{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric,load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We must tokenise the input before feeding to the model. We use the tokenizer from the pretrained model.\n",
    "- The dataset must have the label column named as 'label', to be trained using Trainer API. It is preferable to keep the text column as 'text'. However since we are tokenising the text column, it can be named anything, as we just pass the tokenised columns input_ids and attention_mask to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model_name = \"roberta-base-emotion-prediction-phr-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"anger\":0,\n",
    "    \"anticipation\":1,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":1,\n",
    "    \"joy\":1,\n",
    "    \"love\":1,\n",
    "    \"optimism\":1,\n",
    "    \"pessimism\":1,\n",
    "    \"sadness\":1,\n",
    "    \"surprise\":1,\n",
    "    \"trust\":1\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    0:\"anger\",\n",
    "    1:\"anticipation\",\n",
    "    2:\"disgust\",\n",
    "    3:\"fear\",\n",
    "    4:\"joy\",\n",
    "    5:\"love\",\n",
    "    6:\"optimism\",\n",
    "    7:\"pessimism\",\n",
    "    8:\"sadness\",\n",
    "    9:\"surprise\",\n",
    "    10:\"trust\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokeniser = AutoTokenizer.from_pretrained(\"roberta-base\",problem_type =\"multi_label_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", problem_type =\"multi_label_classification\", num_labels=11,label2id=label2id,id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"vibhorag101/sem_eval_2018_task_1_english_cleaned_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniseDataset(dataset):\n",
    "    return(tokeniser(dataset[\"text\"],padding=\"max_length\",truncation=True))\n",
    "\n",
    "#\n",
    "dataset.set_format(\"torch\")\n",
    "dataset = dataset.map(lambda x : {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"]).rename_column(\"float_labels\", \"labels\")\n",
    "\n",
    "column_names = dataset[\"train\"].column_names\n",
    "column_names.remove(\"labels\")\n",
    "tokenisedDataset = dataset.map(tokeniseDataset,batched=True,remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 6838\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 3259\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 3259\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "trainTokeniseDataset = tokenisedDataset[\"train\"]\n",
    "testTokenisedDataset = tokenisedDataset[\"test\"]\n",
    "valTokenisedDataset = tokenisedDataset[\"test\"]\n",
    "print(trainTokeniseDataset)\n",
    "print(valTokenisedDataset)\n",
    "print(testTokenisedDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score,precision_score,recall_score\n",
    "\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    sigmoid_pred = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into predicted labels\n",
    "    y_pred  = np.where(sigmoid_pred > threshold, 1, 0)\n",
    "\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    metrics = { 'accuracy': accuracy,\n",
    "                'micro_precision': precision,\n",
    "                'micro_recall': recall,\n",
    "                'micro_f1': f1_micro_average,\n",
    "                'micro_roc_auc': roc_auc,\n",
    "                }\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    return multi_label_metrics(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvibhor20349\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ba24fdaf7942d3a2c5898ba5af3b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113506599536372, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/phr-mental-chat/finetuneModel/wandb/run-20231126_155509-x3sh3za7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vibhor20349/huggingface/runs/x3sh3za7' target=\"_blank\">roberta-base-emotion-prediction-phr-2</a></strong> to <a href='https://wandb.ai/vibhor20349/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vibhor20349/huggingface' target=\"_blank\">https://wandb.ai/vibhor20349/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vibhor20349/huggingface/runs/x3sh3za7' target=\"_blank\">https://wandb.ai/vibhor20349/huggingface/runs/x3sh3za7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vibhor20349/huggingface/runs/x3sh3za7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efe787d0880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"huggingface\", entity=\"vibhor20349\", name=finetune_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=finetune_model_name,\n",
    "    report_to = 'wandb',\n",
    "    learning_rate=2e-5, # recommended in roberta paper\n",
    "    num_train_epochs=3, #recommended in bert paper\n",
    "    per_device_train_batch_size=16, # recommended in roberta paper\n",
    "    per_device_eval_batch_size=16, # recommended in roberta paper\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps = 1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=500,\n",
    "    push_to_hub=True #to clone the training repo just before starting to train, so push to hub works\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/vibhorag101/roberta-base-emotion-prediction-phr into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model= model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainTokeniseDataset,\n",
    "    eval_dataset=valTokenisedDataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokeniser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.685547947883606,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_micro_precision': 0.1971156796563363,\n",
       " 'eval_micro_recall': 0.40818401321641884,\n",
       " 'eval_micro_f1': 0.2658500248303261,\n",
       " 'eval_micro_roc_auc': 0.4703000123265797,\n",
       " 'eval_runtime': 30.2704,\n",
       " 'eval_samples_per_second': 107.663,\n",
       " 'eval_steps_per_second': 6.739}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(trainer.predict(testTokenisedDataset))\n",
    "trainer.evaluate(eval_dataset=testTokenisedDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# #trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(finetune_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(finetune_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1404,  0.1603,  0.0559, -0.0134, -0.2044, -0.2912,  0.0414,  0.0249,\n",
      "         -0.2535,  0.0668, -0.0723]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "[['anticipation', 'disgust', 'optimism', 'pessimism', 'surprise']]\n"
     ]
    }
   ],
   "source": [
    "### IF we want to make predictions\n",
    "input_text = \"You are an extremely good person. Thank you so much\"\n",
    "inputs = tokeniser(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    ## BERT expects the keyword agruments \"token_type_ids\" and \"attention_mask\" in input.\n",
    "    # so we convert inputs dictionary to keyword arguments using ** before passing to the model\n",
    "    inputs.to('cuda')\n",
    "    outputs = model(**inputs)\n",
    "    ## output of Bert contains logits for each class, pooled output and hidden states and attentions\n",
    "\n",
    "# Extract the predicted logits(raw values for each class)\n",
    "logits = outputs.logits\n",
    "print(outputs)\n",
    "\n",
    "## logits are just raw values for each class. To get probabilities we use softmax\n",
    "sigmoid_logits = torch.nn.functional.sigmoid(logits)\n",
    "predictions = np.where(sigmoid_logits.cpu() > 0.5, 1, 0)\n",
    "\n",
    "# Get the predicted labels from id2label dictionary\n",
    "label_predictions = []\n",
    "for pred in predictions:\n",
    "    label_predictions.append([id2label[i] for i, val in enumerate(pred) if val])\n",
    "print(label_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
