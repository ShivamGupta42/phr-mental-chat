{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "import re\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jerryjalapeno/nart-100k-synthetic\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 30000 samples from the dataset\n",
    "# dataset['train'] = dataset['train'].shuffle(seed=42).select(range(2000))\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train_test_val split\n",
    "train_test_split = dataset[\"train\"].train_test_split(test_size=0.3)\n",
    "train_val_split = train_test_split['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "print(train_test_split)\n",
    "print(train_val_split)\n",
    "\n",
    "train_test_val_split = DatasetDict({\n",
    "    \"train\": train_test_split['train'],\n",
    "    \"test\": train_val_split['train'],\n",
    "    \"val\": train_val_split['test']\n",
    "})\n",
    "\n",
    "print(train_test_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful and joyous mental therapy assistant. Always answer as helpfully and cheerfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "def preprocessText(text):\n",
    "    text = re.sub(r'Alex', '', text)\n",
    "    text = re.sub(r'Charlie', '', text)\n",
    "    # remove \", \" when it appears at the start of a sentence\n",
    "    text = re.sub(r'^, ', '', text)\n",
    "    # remove \" .\" with \".\"\n",
    "    text = re.sub(r' \\.', '.', text)\n",
    "    # remove \" ,\" with \",\"\n",
    "    text = re.sub(r' ,', ',', text)\n",
    "    # remove \" ?\" with \"?\"\n",
    "    text = re.sub(r' \\?', '?', text)\n",
    "    # remove \",.\" with \".\"\n",
    "    text = re.sub(r',\\.', '.', text)\n",
    "    # remove \",?\" with \"?\"\n",
    "    text = re.sub(r',\\?', '?', text)\n",
    "    # remove more than one space\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "\n",
    "def transform_dataset(data_row):\n",
    "    id = data_row['id']\n",
    "    data_row = data_row['conversations']\n",
    "    for conv in data_row:\n",
    "        if conv['from'] == 'human':\n",
    "            conv['role'] = \"user\"\n",
    "        elif conv['from'] == 'gpt':\n",
    "            conv['role'] = \"assistant\"\n",
    "        \n",
    "        conv['content'] = preprocessText(conv['value'])\n",
    "        del conv['from']\n",
    "        del conv['value']\n",
    "    \n",
    "    system_dict = {}\n",
    "    system_dict['role'] = \"system\"\n",
    "    system_dict['content'] = SYSTEM_PROMPT\n",
    "    data_row.insert(0, system_dict)\n",
    "    # in conversational format the features name is \"messages\"\n",
    "    return {\"messages\": data_row}\n",
    "\n",
    "train_test_val_split = train_test_val_split.map(transform_dataset, remove_columns=['conversations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_val_split['train'][0]['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"llama-2-7b-chat-hf-phr_mental_therapy-2\")\n",
    "print(tokenizer.apply_chat_template(train_test_val_split['train'][0]['messages'],tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_val_split.push_to_hub(\"phr-mental-therapy-dataset-conversational-format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the max sequence length of the tokenized messages                                          \n",
    "train_test_val_split = train_test_val_split.map(lambda x: {\"input_ids\": tokenizer.apply_chat_template(x[\"messages\"])})\n",
    "print(train_test_val_split[\"train\"][0][\"input_ids\"] )\n",
    "# get the maximum length of the formatted chat\n",
    "max_length = max(len(chat) for chat in train_test_val_split[\"train\"][\"input_ids\"])\n",
    "print(max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
